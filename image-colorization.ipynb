{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1462296,"sourceType":"datasetVersion","datasetId":857191}],"dockerImageVersionId":30716,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Image Colorization using GANs üß®</h1></span> \n\nIn this notebook you'll learn to implement GANs, unets, and realize how pretraining is used in improve the model performance.\nThis notebook tackles the task of image colorization using conditional GANs. The implementation is inspired from pix2pix paper.\n# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Intro: Generative Adversarial Networks üç≠<a id=\"Intro\"></a></h1></span>\nThis module contains brief introduction to GANs. Feel free to skip it if you're familiar with it.\n\nA GAN model comprises of 2 sub-models:\n\n* The <b>generator</b> learns to generate plausible data. The generated instances become negative training examples for the discriminator.\n* The <b>discriminator</b> learns to distinguish the generator's fake data from real data. The discriminator penalizes the generator for producing implausible results.\n\nWe simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates\nthe probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to ${1 \\over 2}$ everywhere. ","metadata":{}},{"cell_type":"markdown","source":"\n<img src=\"https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41524-020-00352-0/MediaObjects/41524_2020_352_Fig1_HTML.png\" width=\"800\"></img>\n","metadata":{}},{"cell_type":"markdown","source":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Install Required Libraries üì¶ <a id=\"Installing required libraries\"></a></h1></span>","metadata":{}},{"cell_type":"code","source":"!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-06-01T17:18:45.906256Z","iopub.execute_input":"2024-06-01T17:18:45.906613Z","iopub.status.idle":"2024-06-01T17:18:58.930938Z","shell.execute_reply.started":"2024-06-01T17:18:45.906583Z","shell.execute_reply":"2024-06-01T17:18:58.929788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Import Required Libraries üß∫<a id=\"Importing libraries\"></a></h1></span>","metadata":{}},{"cell_type":"markdown","source":"### 1.1- Loading Image¬†Paths","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\nimport time\n\n# For data manipulation\nimport numpy as np\nfrom PIL import Image\nimport cv2 as cv\nfrom pathlib import Path\n\n# Pytorch imports\nimport torch\nfrom torch import nn, optim\nfrom torchvision import transforms\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import Dataset, DataLoader\nimport torchsummary\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\n# Utils\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nfrom skimage.color import rgb2lab, lab2rgb","metadata":{"execution":{"iopub.status.busy":"2024-06-02T17:22:37.885211Z","iopub.execute_input":"2024-06-02T17:22:37.885912Z","iopub.status.idle":"2024-06-02T17:22:46.323013Z","shell.execute_reply.started":"2024-06-02T17:22:37.885880Z","shell.execute_reply":"2024-06-02T17:22:46.321823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install fastai==2.4\nfrom fastai.vision.learner import create_body\nfrom torchvision.models.resnet import resnet18\nfrom fastai.vision.models.unet import DynamicUnet","metadata":{"execution":{"iopub.status.busy":"2024-06-01T17:19:05.057772Z","iopub.execute_input":"2024-06-01T17:19:05.058194Z","iopub.status.idle":"2024-06-01T17:19:09.738710Z","shell.execute_reply.started":"2024-06-01T17:19:05.058162Z","shell.execute_reply":"2024-06-01T17:19:09.737942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Making Dataset and Dataloadersü•°<a id=\"Datasets and Dataloaders\"></a></h1></span>\nWe'll be using a subset of <b>COCO dataset</b>: 8000 training images and 2000 validation images.","metadata":{}},{"cell_type":"code","source":"# setting seed\nnp.random.seed(123)\n\npaths = glob.glob('/kaggle/input/coco-2017-dataset/coco2017/train2017' + \"/*.jpg\") # Grabbing all the image file paths\npaths_subset = np.random.choice(paths, 10_000, replace=False) # choosing 10000 paths randomly\nrand_idxs = np.random.permutation(10_000) # generate a numpy array of numbers from 0 to 9999 in any random order\ntrain_idxs = rand_idxs[:8000]\nval_idxs = rand_idxs[8000:]\ntrain_paths = paths_subset[train_idxs]\nval_paths = paths_subset[val_idxs]\n\nprint(\"Number of training images: \",len(train_paths))\nprint(\"Number of testing images: \",len(val_paths))","metadata":{"execution":{"iopub.status.busy":"2024-06-01T17:19:09.740777Z","iopub.execute_input":"2024-06-01T17:19:09.741069Z","iopub.status.idle":"2024-06-01T17:19:11.083120Z","shell.execute_reply.started":"2024-06-01T17:19:09.741044Z","shell.execute_reply":"2024-06-01T17:19:11.082090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualizing the dataset\n_, axes = plt.subplots(4, 4, figsize=(10, 10))\nfor ax, img_path in zip(axes.flatten(), train_paths):\n    ax.imshow(Image.open(img_path))\n    ax.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2024-06-01T17:23:05.021207Z","iopub.execute_input":"2024-06-01T17:23:05.021995Z","iopub.status.idle":"2024-06-01T17:23:06.618527Z","shell.execute_reply.started":"2024-06-01T17:23:05.021961Z","shell.execute_reply":"2024-06-01T17:23:06.617247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SIZE = 256\nclass ColorizationDataset(Dataset):\n    def __init__(self, paths, split='train'):\n        if split == 'train':\n            self.transforms = transforms.Compose([\n                transforms.Resize((SIZE, SIZE),  Image.BICUBIC),\n                transforms.RandomHorizontalFlip(), # A little data augmentation!\n            ])\n        elif split == 'val':\n            self.transforms = transforms.Resize((SIZE, SIZE),  Image.BICUBIC)\n        \n        self.split = split\n        self.size = SIZE\n        self.paths = paths\n    \n    def __getitem__(self, idx):\n        img = Image.open(self.paths[idx]).convert(\"RGB\")\n        img = self.transforms(img)\n        img = np.array(img)\n        img_lab = rgb2lab(img).astype(\"float32\") # Converting RGB to L*a*b\n        img_lab = transforms.ToTensor()(img_lab)\n        L = img_lab[[0], ...] / 50. - 1. # Between -1 and 1\n        ab = img_lab[[1, 2], ...] / 110. # Between -1 and 1\n        \n        return {'L': L, 'ab': ab}\n    \n    def __len__(self):\n        return len(self.paths)\n\ndef make_dataloaders(batch_size=16, n_workers=2, pin_memory=True, **kwargs): # A handy function to make our dataloaders\n    dataset = ColorizationDataset(**kwargs)\n    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=n_workers,\n                            pin_memory=pin_memory)\n    return dataloader","metadata":{"execution":{"iopub.status.busy":"2024-06-01T17:23:15.075198Z","iopub.execute_input":"2024-06-01T17:23:15.075541Z","iopub.status.idle":"2024-06-01T17:23:15.086061Z","shell.execute_reply.started":"2024-06-01T17:23:15.075514Z","shell.execute_reply":"2024-06-01T17:23:15.085101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dl = make_dataloaders(paths=train_paths, split='train')\nval_dl = make_dataloaders(paths=val_paths, split='val')\nprint(\"Number of training batches: \",len(train_paths)) # 8000 / dataloader_batch_size(=16)\nprint(\"Number of testing batches: \",len(val_paths)) # 2000 / 16\ndata = next(iter(train_dl))\nLs, abs_ = data['L'], data['ab']\nprint(Ls.shape, abs_.shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-01T17:23:55.169285Z","iopub.execute_input":"2024-06-01T17:23:55.169659Z","iopub.status.idle":"2024-06-01T17:23:55.825339Z","shell.execute_reply.started":"2024-06-01T17:23:55.169622Z","shell.execute_reply":"2024-06-01T17:23:55.824132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Generator‚ú®<a id=\"Model Architecture\"></a></h1></span>\n\n![unet](https://raw.githubusercontent.com/prabhanjan-jadhav/image-colorization-using-gans/main/images/UNet%20architechture.png)","metadata":{}},{"cell_type":"code","source":"class UnetBlock(nn.Module):\n    def __init__(self, nf, ni, submodule=None, input_c=None, dropout=False,\n                 innermost=False, outermost=False):\n        super().__init__()\n        self.outermost = outermost\n        if input_c is None: input_c = nf\n        downconv = nn.Conv2d(input_c, ni, kernel_size=4,\n                             stride=2, padding=1, bias=False)\n        downrelu = nn.LeakyReLU(0.2, True)\n        downnorm = nn.BatchNorm2d(ni)\n        uprelu = nn.ReLU(True)\n        upnorm = nn.BatchNorm2d(nf)\n        \n        if outermost:\n            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n                                        stride=2, padding=1)\n            down = [downconv]\n            up = [uprelu, upconv, nn.Tanh()]\n            model = down + [submodule] + up\n        elif innermost:\n            upconv = nn.ConvTranspose2d(ni, nf, kernel_size=4,\n                                        stride=2, padding=1, bias=False)\n            down = [downrelu, downconv]\n            up = [uprelu, upconv, upnorm]\n            model = down + up\n        else:\n            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n                                        stride=2, padding=1, bias=False)\n            down = [downrelu, downconv, downnorm]\n            up = [uprelu, upconv, upnorm]\n            if dropout: up += [nn.Dropout(0.5)]\n            model = down + [submodule] + up\n        self.model = nn.Sequential(*model)\n    \n    def forward(self, x):\n        if self.outermost:\n            return self.model(x)\n        else:\n            return torch.cat([x, self.model(x)], 1)\n\nclass Unet(nn.Module):\n    def __init__(self, input_c=1, output_c=2, n_down=8, num_filters=64):\n        super().__init__()\n        unet_block = UnetBlock(num_filters * 8, num_filters * 8, innermost=True)\n        for _ in range(n_down - 5):\n            unet_block = UnetBlock(num_filters * 8, num_filters * 8, submodule=unet_block, dropout=True)\n        out_filters = num_filters * 8\n        for _ in range(3):\n            unet_block = UnetBlock(out_filters // 2, out_filters, submodule=unet_block)\n            out_filters //= 2\n        self.model = UnetBlock(output_c, out_filters, input_c=input_c, submodule=unet_block, outermost=True)\n    \n    def forward(self, x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2024-06-01T17:24:01.629213Z","iopub.execute_input":"2024-06-01T17:24:01.630065Z","iopub.status.idle":"2024-06-01T17:24:01.646981Z","shell.execute_reply.started":"2024-06-01T17:24:01.630021Z","shell.execute_reply":"2024-06-01T17:24:01.646081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Unet()\n\nif torch.cuda.is_available():\n    model.cuda()\ntorchsummary.summary(model, input_size=(1,256,256),batch_size=1)","metadata":{"execution":{"iopub.status.busy":"2024-06-01T17:24:30.217612Z","iopub.execute_input":"2024-06-01T17:24:30.218003Z","iopub.status.idle":"2024-06-01T17:24:30.805144Z","shell.execute_reply.started":"2024-06-01T17:24:30.217973Z","shell.execute_reply":"2024-06-01T17:24:30.804154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Discriminator </h1></span>\n\nThe architecture of our discriminator is rather straight forward. This code implements a model by stacking blocks of Conv-BatchNorm-LeackyReLU to decide whether the input image is fake or real. Notice that the first and last blocks do not use normalization and the last block has no activation function (it is embedded in the loss function we will use).","metadata":{}},{"cell_type":"code","source":"class PatchDiscriminator(nn.Module):\n    def __init__(self, input_c, num_filters=64, n_down=3):\n        super().__init__()\n        # Check if a GPU is available\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        model = [self.get_layers(input_c, num_filters, norm=False)]\n        model += [self.get_layers(num_filters * 2 ** i, num_filters * 2 ** (i + 1), s=1 if i == (n_down-1) else 2) \n                          for i in range(n_down)] # the 'if' statement is taking care of not using\n                                                  # stride of 2 for the last block in this loop\n        model += [self.get_layers(num_filters * 2 ** n_down, 1, s=1, norm=False, act=False)] # Make sure to not use normalization or\n                                                                                             # activation for the last layer of the model\n        self.model = nn.Sequential(*model)                                                   \n        # Move the network to the GPU if available\n        self.to(device)\n    def get_layers(self, ni, nf, k=4, s=2, p=1, norm=True, act=True): # when needing to make some repeatitive blocks of layers,\n        layers = [nn.Conv2d(ni, nf, k, s, p, bias=not norm)]          # it's always helpful to make a separate method for that purpose\n        if norm: layers += [nn.BatchNorm2d(nf)]\n        if act: layers += [nn.LeakyReLU(0.2, True)]\n        return nn.Sequential(*layers)\n    \n    def forward(self, x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2024-06-01T17:24:35.928509Z","iopub.execute_input":"2024-06-01T17:24:35.929355Z","iopub.status.idle":"2024-06-01T17:24:35.939318Z","shell.execute_reply.started":"2024-06-01T17:24:35.929321Z","shell.execute_reply":"2024-06-01T17:24:35.938329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torchsummary.summary(PatchDiscriminator(3), input_size=(3, 194, 194),batch_size=16)","metadata":{"execution":{"iopub.status.busy":"2024-06-01T17:24:39.517896Z","iopub.execute_input":"2024-06-01T17:24:39.518275Z","iopub.status.idle":"2024-06-01T17:24:39.558703Z","shell.execute_reply.started":"2024-06-01T17:24:39.518246Z","shell.execute_reply":"2024-06-01T17:24:39.557840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Loss Function üß≠<a id=\"Loss function\"></a></h1></span>\n* **Loss function we optimize** :\n\\begin{equation}\nG^* = arg min_G max_D L_{cGAN} (G,D) + \\lambda L_{L1} (G)\n\\end{equation}\n\n\n* **L1 Loss** : \n\\begin{equation}\nL_{L1} (G) = \\mathbb{E}_{x,y,z}[\\|y-G(x,z)\\|_1]\n\\end{equation}\n\n\n* **GAN Loss** : \n\\begin{equation}\nL_{cGAN}(G,D) = \\mathbb{E}_{x,y}[logD(x,y)] + \\mathbb{E}_{x,z}[log(1-D(x, G(x,z))]\n\\end{equation}\nWhere **x** as the grayscale image, **z** as the input noise for the generator, and **y** as the 2-channel output we want from the generator (it can also represent the 2 color channels of a real image). Also, **G** is the generator model and **D** is the discriminator. \n","metadata":{}},{"cell_type":"code","source":"class GANLoss(nn.Module):\n    def __init__(self, gan_mode='vanilla', real_label=1.0, fake_label=0.0):\n        super().__init__()\n        self.register_buffer('real_label', torch.tensor(real_label))\n        self.register_buffer('fake_label', torch.tensor(fake_label))\n        if gan_mode == 'vanilla':\n            self.loss = nn.BCEWithLogitsLoss()\n        elif gan_mode == 'lsgan':\n            self.loss = nn.MSELoss()\n    \n    def get_labels(self, preds, target_is_real):\n        if target_is_real:\n            labels = self.real_label\n        else:\n            labels = self.fake_label\n        return labels.expand_as(preds)\n    \n    def __call__(self, preds, target_is_real):\n        labels = self.get_labels(preds, target_is_real)\n        loss = self.loss(preds, labels)\n        return loss","metadata":{"execution":{"iopub.status.busy":"2024-06-01T17:24:44.120507Z","iopub.execute_input":"2024-06-01T17:24:44.121247Z","iopub.status.idle":"2024-06-01T17:24:44.128950Z","shell.execute_reply.started":"2024-06-01T17:24:44.121213Z","shell.execute_reply":"2024-06-01T17:24:44.127938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Model Initialization‚öôÔ∏è</h1></span>","metadata":{}},{"cell_type":"code","source":"def init_weights(net, init='norm', gain=0.02):\n    \n    def init_func(m):\n        classname = m.__class__.__name__\n        if hasattr(m, 'weight') and 'Conv' in classname:\n            if init == 'norm':\n                nn.init.normal_(m.weight.data, mean=0.0, std=gain)\n            elif init == 'xavier':\n                nn.init.xavier_normal_(m.weight.data, gain=gain)\n            elif init == 'kaiming':\n                nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n            \n            if hasattr(m, 'bias') and m.bias is not None:\n                nn.init.constant_(m.bias.data, 0.0)\n        elif 'BatchNorm2d' in classname:\n            nn.init.normal_(m.weight.data, 1., gain)\n            nn.init.constant_(m.bias.data, 0.)\n            \n    net.apply(init_func)\n    print(f\"model initialized with {init} initialization\")\n    return net\n\ndef init_model(model, device):\n    model = model.to(device)\n    model = init_weights(model)\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-06-01T17:25:52.623018Z","iopub.execute_input":"2024-06-01T17:25:52.623386Z","iopub.status.idle":"2024-06-01T17:25:52.632704Z","shell.execute_reply.started":"2024-06-01T17:25:52.623356Z","shell.execute_reply":"2024-06-01T17:25:52.631779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Modelü™Ñ</h1></span> \n# Putting Everything together","metadata":{}},{"cell_type":"code","source":"class MainModel(nn.Module):\n    def __init__(self, net_G=None, lr_G=2e-4, lr_D=2e-4, \n                 beta1=0.5, beta2=0.999, lambda_L1=100.):\n        super().__init__()\n        \n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.lambda_L1 = lambda_L1\n        \n        if net_G is None:\n            self.net_G = init_model(Unet(input_c=1, output_c=2, n_down=8, num_filters=64), self.device)\n        else:\n            self.net_G = net_G.to(self.device)\n        self.net_D = init_model(PatchDiscriminator(input_c=3, n_down=3, num_filters=64), self.device)\n        self.GANcriterion = GANLoss(gan_mode='vanilla').to(self.device)\n        self.L1criterion = nn.L1Loss()\n        self.opt_G = optim.Adam(self.net_G.parameters(), lr=lr_G, betas=(beta1, beta2))\n        self.opt_D = optim.Adam(self.net_D.parameters(), lr=lr_D, betas=(beta1, beta2))\n    \n    def set_requires_grad(self, model, requires_grad=True):\n        for p in model.parameters():\n            p.requires_grad = requires_grad\n        \n    def setup_input(self, data):\n        self.L = data['L'].to(self.device)\n        self.ab = data['ab'].to(self.device)\n        \n    def forward(self):\n        self.fake_color = self.net_G(self.L)\n    \n    def backward_D(self):\n        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n        fake_preds = self.net_D(fake_image.detach())\n        self.loss_D_fake = self.GANcriterion(fake_preds, False)\n        real_image = torch.cat([self.L, self.ab], dim=1)\n        real_preds = self.net_D(real_image)\n        self.loss_D_real = self.GANcriterion(real_preds, True)\n        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n        self.loss_D.backward()\n    \n    def backward_G(self):\n        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n        fake_preds = self.net_D(fake_image)\n        self.loss_G_GAN = self.GANcriterion(fake_preds, True)\n        self.loss_G_L1 = self.L1criterion(self.fake_color, self.ab) * self.lambda_L1\n        self.loss_G = self.loss_G_GAN + self.loss_G_L1\n        self.loss_G.backward()\n    \n    def optimize(self):\n        self.forward()\n        self.net_D.train()\n        self.set_requires_grad(self.net_D, True)\n        self.opt_D.zero_grad()\n        self.backward_D()\n        self.opt_D.step()\n        \n        self.net_G.train()\n        self.set_requires_grad(self.net_D, False)\n        self.opt_G.zero_grad()\n        self.backward_G()\n        self.opt_G.step()","metadata":{"execution":{"iopub.status.busy":"2024-06-01T17:25:58.361735Z","iopub.execute_input":"2024-06-01T17:25:58.362468Z","iopub.status.idle":"2024-06-01T17:25:58.378759Z","shell.execute_reply.started":"2024-06-01T17:25:58.362436Z","shell.execute_reply":"2024-06-01T17:25:58.377870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Utility functionsüéà</h1></span>","metadata":{}},{"cell_type":"code","source":"class AverageMeter:\n    def __init__(self):\n        self.reset()\n        \n    def reset(self):\n        self.count, self.avg, self.sum = [0.] * 3\n    \n    def update(self, val, count=1):\n        self.count += count\n        self.sum += count * val\n        self.avg = self.sum / self.count\n\ndef create_loss_meters():\n    loss_D_fake = AverageMeter()\n    loss_D_real = AverageMeter()\n    loss_D = AverageMeter()\n    loss_G_GAN = AverageMeter()\n    loss_G_L1 = AverageMeter()\n    loss_G = AverageMeter()\n    \n    return {'loss_D_fake': loss_D_fake,\n            'loss_D_real': loss_D_real,\n            'loss_D': loss_D,\n            'loss_G_GAN': loss_G_GAN,\n            'loss_G_L1': loss_G_L1,\n            'loss_G': loss_G}\n\ndef update_losses(model, loss_meter_dict, count):\n    for loss_name, loss_meter in loss_meter_dict.items():\n        loss = getattr(model, loss_name)\n        loss_meter.update(loss.item(), count=count)\n\ndef lab_to_rgb(L, ab):\n    \"\"\"\n    Takes a batch of images\n    \"\"\"\n    \n    L = (L + 1.) * 50.\n    ab = ab * 110.\n    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n    rgb_imgs = []\n    for img in Lab:\n        img_rgb = lab2rgb(img)\n        rgb_imgs.append(img_rgb)\n    return np.stack(rgb_imgs, axis=0)\n    \ndef visualize(model, data, save=True,num=5):\n    model.net_G.eval()\n    with torch.no_grad():\n        model.setup_input(data)\n        model.forward()\n    model.net_G.train()\n    fake_color = model.fake_color.detach()\n    real_color = model.ab\n    L = model.L\n    fake_imgs = lab_to_rgb(L, fake_color)\n    real_imgs = lab_to_rgb(L, real_color)\n    fig = plt.figure(figsize=(15, 8))\n    for i in range(num):\n        ax = plt.subplot(3, num, i + 1)\n        ax.imshow(L[i][0].cpu(), cmap='gray')\n        ax.axis(\"off\")\n        ax = plt.subplot(3, num, i + 1 + num)\n        ax.imshow(fake_imgs[i])\n        ax.axis(\"off\")\n        ax = plt.subplot(3, num, i + 1 + 2*num)\n        ax.imshow(real_imgs[i])\n        ax.axis(\"off\")\n    plt.show()\n    if save:\n        fig.savefig(f\"colorization_{time.time()}.png\")\n        \ndef log_results(loss_meter_dict):\n    for loss_name, loss_meter in loss_meter_dict.items():\n        print(f\"{loss_name}: {loss_meter.avg:.5f}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-01T17:27:10.557033Z","iopub.execute_input":"2024-06-01T17:27:10.557424Z","iopub.status.idle":"2024-06-01T17:27:10.573829Z","shell.execute_reply.started":"2024-06-01T17:27:10.557392Z","shell.execute_reply":"2024-06-01T17:27:10.572744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Trainingüí™</h1></span>\nNow to train the model run the below cell. Running for about 20 epochs, taking approx. 5 mins per epoch, would give reasonable results. \\\nInstead, you can directly download the weights for the model trained for 20 epochs in the following cell.","metadata":{}},{"cell_type":"code","source":"def train_model(model, train_dl, epochs, display_every=200):\n    data = next(iter(val_dl)) # getting a batch for visualizing the model output after fixed intrvals\n    for e in range(epochs):\n        loss_meter_dict = create_loss_meters() # function returing a dictionary of objects to \n        i = 0                                  # log the losses of the complete network\n        for data in tqdm(train_dl):\n            model.setup_input(data) \n            model.optimize()\n            update_losses(model, loss_meter_dict, count=data['L'].size(0)) # function updating the log objects\n            i += 1\n            if i % display_every == 0:\n                print(f\"\\nEpoch {e+1}/{epochs}\")\n                print(f\"Iteration {i}/{len(train_dl)}\")\n                log_results(loss_meter_dict) # function to print out the losses\n                visualize(model, data, save=False) # function displaying the model's outputs\n\nmodel = MainModel()\ntrain_model(model, train_dl, 20)","metadata":{"execution":{"iopub.status.busy":"2024-06-01T17:27:48.045806Z","iopub.execute_input":"2024-06-01T17:27:48.046644Z","iopub.status.idle":"2024-06-01T17:27:48.696217Z","shell.execute_reply.started":"2024-06-01T17:27:48.046601Z","shell.execute_reply":"2024-06-01T17:27:48.695181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generating output on validation dataset\nfor data in tqdm(val_dl):\n    model.setup_input(data)\n    model.optimize()\n#     visualize(model, data, save=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-01T17:27:53.563820Z","iopub.execute_input":"2024-06-01T17:27:53.564528Z","iopub.status.idle":"2024-06-01T17:29:01.595181Z","shell.execute_reply.started":"2024-06-01T17:27:53.564491Z","shell.execute_reply":"2024-06-01T17:29:01.594086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style = \"font-size:60px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">A new strategy‚ÄäüöÄ<a id=\"Another approach\"></a></h1>\nThis module uses fastai and torchvision models to build the generator model. \n\nA ResNet pretrained on ImageNet classification task is added as a backbone to the UNet of the generator. The discriminator is the same as before.","metadata":{}},{"cell_type":"code","source":"def build_res_unet(n_input=1, n_output=2, size=256):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    body = create_body(resnet18(), pretrained=True, n_in=n_input, cut=-2)\n    net_G = DynamicUnet(body, n_output, (size, size)).to(device)\n    return net_G","metadata":{"execution":{"iopub.status.busy":"2024-06-01T17:29:15.387373Z","iopub.execute_input":"2024-06-01T17:29:15.388294Z","iopub.status.idle":"2024-06-01T17:29:15.394165Z","shell.execute_reply.started":"2024-06-01T17:29:15.388256Z","shell.execute_reply":"2024-06-01T17:29:15.393190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With this simple function, we pretrain the generator for 20 epochs and then we save its weights. This will take an hour on Colab. In the following section, we will use this model as the generator for our GAN and train the whole network as before:","metadata":{}},{"cell_type":"code","source":"def pretrain_generator(net_G, train_dl, opt, criterion, epochs):\n    ''' Pretraining generator on image colorization task using L1 loss.\n    ResNet backbone has pretrained weights'''\n    for e in range(epochs):\n        loss_meter = AverageMeter()\n        for data in tqdm(train_dl):\n            L, ab = data['L'].to(device), data['ab'].to(device)\n            preds = net_G(L)\n            loss = criterion(preds, ab)\n            opt.zero_grad()\n            loss.backward()\n            opt.step()\n            \n            loss_meter.update(loss.item(), L.size(0))\n            \n        print(f\"Epoch {e + 1}/{epochs}\")\n        print(f\"L1 Loss: {loss_meter.avg:.5f}\")\n\nnet_G = build_res_unet(n_input=1, n_output=2, size=256)\nopt = optim.Adam(net_G.parameters(), lr=1e-4)\ncriterion = nn.L1Loss()  \npretrain_generator(net_G, train_dl, opt, criterion, 20)\ntorch.save(net_G.state_dict(), \"res18-unet.pt\")","metadata":{"execution":{"iopub.status.busy":"2024-06-01T17:29:22.317383Z","iopub.execute_input":"2024-06-01T17:29:22.318244Z","iopub.status.idle":"2024-06-01T19:08:05.867325Z","shell.execute_reply.started":"2024-06-01T17:29:22.318203Z","shell.execute_reply":"2024-06-01T19:08:05.866208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nTraining the entire model for 20 epochs\n'''\nnet_G = build_res_unet(n_input=1, n_output=2, size=256)\nnet_G.load_state_dict(torch.load(\"res18-unet.pt\", map_location=device))\nmodel = MainModel(net_G=net_G)\ntrain_model(model, train_dl, 20)\ntorch.save(model.state_dict(), \"final_model_weights.pt\")","metadata":{"execution":{"iopub.status.busy":"2024-06-01T19:10:45.555666Z","iopub.execute_input":"2024-06-01T19:10:45.556639Z","iopub.status.idle":"2024-06-01T19:36:27.493021Z","shell.execute_reply.started":"2024-06-01T19:10:45.556594Z","shell.execute_reply":"2024-06-01T19:36:27.491770Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net_G = build_res_unet(n_input=1, n_output=2, size=256)\nnet_G.load_state_dict(torch.load(\"res18-unet.pt\", map_location=device))\nmodel = MainModel(net_G=net_G)\nmodel.load_state_dict(torch.load(\"final_model_weights.pt\", map_location=device))","metadata":{"execution":{"iopub.status.busy":"2024-06-02T12:04:06.305023Z","iopub.execute_input":"2024-06-02T12:04:06.306041Z","iopub.status.idle":"2024-06-02T12:04:07.812764Z","shell.execute_reply.started":"2024-06-02T12:04:06.305989Z","shell.execute_reply":"2024-06-02T12:04:07.811609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nGenerate output on your own set of images\n\n'''\nimport random\nimg_path = '/kaggle/input/coco-2017-dataset/coco2017/test2017/'\nprint(img_path)\npaths = glob.glob(img_path + \"/*\")\ni=int(random.random()*(len(paths)-6))\npaths=paths[i:i+5]\nidxs = np.arange(len(paths))\n\ntest_dl = make_dataloaders(paths=paths, split='val')\nfor data in tqdm(test_dl):\n  model.setup_input(data)\n  model.optimize()\n  visualize(model, data, save=False,num=5)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T17:22:57.680192Z","iopub.execute_input":"2024-06-02T17:22:57.680919Z","iopub.status.idle":"2024-06-02T17:22:58.673309Z","shell.execute_reply.started":"2024-06-02T17:22:57.680885Z","shell.execute_reply":"2024-06-02T17:22:58.671985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}